---
layout: post
title: "aaa"
date: 2020-08-30 18:34:00 -0300
categories: general
---
<img src="images/logos/TClogo.png" width="500">

# PRESENTS

# ROS Developers Live Class n86


![Live Class](images/logos/Live-Class-86.jpg)

# Using OpenCV with ROS?

In this class, you will learn how capture an image from a camera and process it with OpenCV to build a line follower.


**But, why is so important to learn this topic?** 

Because cameras are one of the cheapest sensors, so it would be very interesting for any robot to move using a camera. Also OpenCV is the best image processing library in the world with many state of the art lgorithms for vision tasks.

If you are interested in becoming a **Robotics Developer** you will need to understand messages and how to manage them.

(To know more about becoming a robotics developer, read this guide about <a href="http://www.theconstructsim.com/become-robotics-developer/">How To Become a Robotics Developer</a>)

This rosject has been created by **Ricardo Tellez** from **The Construct**. You can use this rosject freely as long as you keep this notice.

**REQUIREMENTS** :
- **Basics of Linux**. If you don't have that knowledge, [check our FREE online course](https://www.robotigniteacademy.com/en/course/linux-robotics/details/)
<img src="images/logos/Linux.png" width="200">

- **Python Basics**. If you don't have that knowledge, [check our FREE online course](https://www.robotigniteacademy.com/en/course/python-basics/details/)
<img src="images/logos/python.png" width="200">


- **Ros Basics**. If you don't have that knowledge, [check our VERY GOOD online course](https://www.robotigniteacademy.com/en/course/ros-in-5-days/details/)
<img src="images/logos/basics.png" width="200">


- ... That's it! Let's go!

### How to use this ROSject

A <a href="http://rosjects.com">**ROSject**</a> is a **ROS project** packaged in such a way that all the material it contains (**ROS code, Gazebo simulations and Notebooks**) can be shared with any body **using only a web link**. That is what we did with all the attendants to the Live Class, we shared this ROSject with them (so they can have access to all the ROS material they contain).

**Check <a href="https://youtu.be/g2Zg31pc-XM">this Live Class video</a> to learn more about ROSjects and how to create your own ROSjects**.

You will need to have a free account at the <a href="http://rosds.online">ROS Development Studio</a> (ROSDS). Get the account and then follow the indications below.

## Let's setup the environment

Today you're going to use a drone in an environment with a line that we can follow.

### How to launch the simulation

The simulation of today, can be found at the */home/simulation_ws/src*. To launch it, go to the Simulations menu at the top of the window and select **Choose launch file**

<img src="images/useful_images/simulations_menu.png">

From the package **drone_in_line** select the launch file **start_sim.launch**.

You will have something similar to the next image in the simulation.

<img src="images/drone.png" width="600"/>

Now make the robot fly so we can get an image from the camera that points to the bottom.


```python
$ rosservice call engage "{}"
```

Now let's launch the teleop to move the drone to a proper position


```python

```


```bash
%%bash
rostopic pub /cmd_vel geometry_msgs/Twist "linear:
  x: 0.0
  y: 0.0
  z: 0.0
angular:
  x: 0.0
  y: 0.0
  z: 0.1"
```

    Process is terminated.



```bash
%%bash

rostopic pub /cmd_vel geometry_msgs/Twist "linear:
  x: 0.0
  y: 0.0
  z: 0.0
angular:
  x: 0.0
  y: 0.0
  z: 0.0"
```

    Process is terminated.


Let's add the rviz with a camera to visualize what the robot sees


```python
$ rviz
```

Go to top menu and select: **Tools->Graphical tools** to see the rvi< window.

Then add the **Image** visualizer in rviz to see the camera output

<img src="images/rviz.png"/>

## Capturing an image from drone's camera

Let's create a package that will manage the full control code. Inside the *catkin_ws/src* create a new package:


```python
$ cd /home/user/catkin_ws/src
$ catkin_create_pkg line_follower rospy
$ cd line_follower/src
$ touch controller.py
$ chmod +x controller.py
```

Now add the following code to the controller file:


```python
#!/usr/bin/env python

import rospy
from sensor_msgs.msg import Image


class LineFollower(object):

    def __init__(self):
    
        self.image_sub = rospy.Subscriber("/camera/rgb/image_raw",Image,self.camera_callback)

    def camera_callback(self,data):
        pass
        



def main():
    line_follower_object = LineFollower()
    rospy.init_node('line_following_node', anonymous=True)
    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")

if __name__ == '__main__':
    main()
```

## Converting ROS image to OpenCV format

We are going to use the **cv_bridge** which is provided by the package **vision_opencv** (<a href="http://wiki.ros.org/cv_bridge">here the official package</a>).

Add the following code:


```python
from cv_bridge import CvBridge, CvBridgeError
```


```python
self.bridge_object = CvBridge()
```


```python
        try:
            # We select bgr8 because its the OpenCV encoding by default
            cv_image = self.bridge_object.imgmsg_to_cv2(data, desired_encoding="bgr8")
        except CvBridgeError as e:
            print(e)
```

## Detecting the line

Add import of OpenCV:


```python
import cv2
import numpy as np
```

### Scale image down

The goal is to have less data to process


```python
# We get image dimensions and crop the parts of the image we don't need
        # Bear in mind that because the first value of the image matrix is start and second value is down limit.
        # Select the limits so that it gets the line not too close and not too far, and the minimum portion possible
        # To make process faster.
        height, width, channels = cv_image.shape
        descentre = 160
        rows_to_watch = 60
        crop_img = cv_image[(height)/2+descentre:(height)/2+(descentre+rows_to_watch)][1:width]
        
```

### Convert from RGB to HSV 

The goal is to make the color detection independent of light conditions:


```python
hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)
```

### Get only the yellow parts

Everything within the ranges is set white, everything outside, is set to black

Compute the limits:
1. Get the color RGB values you want to follow. In our case, those are R,G,B=(217,255,217)
2. Convert into HSV using the script below


```python
import numpy as np
import cv2
yellow = np.uint8([[[217,255,217]]])
hsv_yellow = cv2.cvtColor(yellow, cv2.COLOR_BGR2HSV)
print(hsv_yellow)
```

    [[[ 60  38 255]]]



```python
# Define the Yellow Colour in HSV
        #RGB
        #[[[222,255,0]]]
        #BGR
        #[[[0,255,222]]]

        upper_yellow = np.array([70,48,255])
        lower_yellow = np.array([50,28,245])

        # Threshold the HSV image to get only yellow colors
        mask = cv2.inRange(hsv, lower_yellow, upper_yellow)
        
```

### Compute the centroid of the blob

We use ImageMoments from OpenCV to compute the blob centroid. The result are the ($c_x, c_y$) coordinates in the image of the center of the blob

Check <a href="https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=moments#moments">this documentation</a> to learn more about moments on OpenCV


```python
        m = cv2.moments(mask, False)
        try:
            cx, cy = m['m10']/m['m00'], m['m01']/m['m00']
        except ZeroDivisionError:
            cy, cx = height/2, width/2
```

## Computing a velocity command to follow the line

### Add publisher to the drone


```python
from geometry_msgs.msg import Twist 
```


```python
self.speed_pub = rospy.Publisher ("/cmd_vel", Twist, queue_size=1)
```

### Compute speed command based on error


```python
        error_x = cx - width / 2;
        speed_cmd = Twist();
        speed_cmd.linear.x = 0.2;
        speed_cmd.angular.z = -error_x / 100;
        
        self.speed_pub.publish(speed_cmd)
```

## Launch the code!


```python
$ rosrun line_follower controller.py
```

### GOOD JOB!

## Mission  completed!!

# Your homework, should you accept to complete it...

# If you liked this video, please support us!
# Really... we need your support!!!!

# How can you support us?
## 1. Subscribe to our ROS online academy and become a Master of ROS Development

Go to our online academy. There is no faster way and funnier to learn ROS because we use the same
method we did here.

**We call the 30/70 method**


* **30% of the time learning theory**
* **70% of the time practicing with simulated robots**

<img src="images/logos/somecourses.png">

### Check it out at http://robotignite.academy

- **ROS Perception in 5 days**. Full course about doing perception with ROS and OpenCV, [check our online course](https://www.robotigniteacademy.com/en/course/ros-perception-in-5-days/details/)
<img src="images/logos/perception.png" width="200">

## 2. Buy one ROS Developers T-shirt or one of our mugs!



<img src="images/logos/mugs.jpeg">

<img src="images/logos/T-shirts.png">

You can buy them at our Teespring area (https://teespring.com/stores/ros-developers)

## 3. Give us a like in Youtube and subscribe to the channel (this is free!)

* **Go to our Youtube Channel (https://www.youtube.com/channel/UCt6Lag-vv25fTX3e11mVY1Q) and subscribe (it is free!!!)**
* **Give us a like to this video**

# KEEP PUSHING YOUR ROS LEARNING WITH PATIENCE AND GOOD HUMOUR!

# Build the future, Become a ROS DEVELOPER

